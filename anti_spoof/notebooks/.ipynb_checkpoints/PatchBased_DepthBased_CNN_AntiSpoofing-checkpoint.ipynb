{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import dlib\n",
    "import tqdm\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import face_recognition as fr\n",
    "\n",
    "### Tensorflow dependencies ###\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from imutils.video import WebcamVideoStream\n",
    "\n",
    "### Other constants ###\n",
    "batch_size = 64\n",
    "\n",
    "real_dir = '/home/minhhieu/Desktop/Hieu/datasets/scene01/real'\n",
    "attack_dir = '/home/minhhieu/Desktop/Hieu/datasets/scene01/attack'\n",
    "\n",
    "real_imgs_dir = '/home/minhhieu/Desktop/Hieu/datasets/scene01/imgs/real'\n",
    "attack_imgs_dir = '/home/minhhieu/Desktop/Hieu/datasets/scene01/imgs/attack'\n",
    "\n",
    "tfrecord_output_path = '/home/minhhieu/Desktop/Hieu/datasets/MSU_MFSD_presentation_attack.tfrecord'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert videos data to images data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 1/69 [00:00<00:11,  6.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Converting /home/minhhieu/Desktop/Hieu/datasets/scene01/real --> /home/minhhieu/Desktop/Hieu/datasets/scene01/imgs/real\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [00:08<00:00,  7.90it/s]\n",
      "  1%|          | 2/210 [00:00<00:11, 17.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Converting /home/minhhieu/Desktop/Hieu/datasets/scene01/attack --> /home/minhhieu/Desktop/Hieu/datasets/scene01/imgs/attack\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 210/210 [00:10<00:00, 19.40it/s]\n",
      "  0%|          | 1/2070 [00:00<04:14,  8.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Cropping face from images in /home/minhhieu/Desktop/Hieu/datasets/scene01/imgs/real...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2070/2070 [03:55<00:00,  8.80it/s]\n",
      "  0%|          | 3/6300 [00:00<05:32, 18.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Cropping face from images in /home/minhhieu/Desktop/Hieu/datasets/scene01/imgs/attack...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6300/6300 [05:09<00:00, 20.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# with face detection\n",
    "def videos_to_images(video_dir, output_imgs_dir, images_per_vid=30):\n",
    "    print(f'[INFO] Converting {video_dir} --> {output_imgs_dir}')\n",
    "    files = glob.glob(f'{video_dir}/*.mov') + glob.glob(f'{video_dir}/*.mp4')\n",
    "    for file in tqdm.tqdm(files):\n",
    "        num_frames = 0\n",
    "        vid_stream = cv2.VideoCapture(file)\n",
    "        \n",
    "        while(num_frames < images_per_vid):\n",
    "            filename = file.split('.')[0]\n",
    "            filename = filename.split('/')[-1]\n",
    "            filename = filename + f\"_{num_frames}.jpg\"\n",
    "            filename = os.path.join(output_imgs_dir, filename)\n",
    "            \n",
    "            ret, img = vid_stream.read()\n",
    "\n",
    "            if(ret):\n",
    "                cv2.imwrite(filename, img)\n",
    "                num_frames += 1\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        vid_stream.release()\n",
    "        \n",
    "def crop_face_images(imgs_dir):\n",
    "    print(f'[INFO] Cropping face from images in {imgs_dir}...')\n",
    "    files = glob.glob(f'{imgs_dir}/*.jpg') + glob.glob(f'{imgs_dir}/*.png') + glob.glob(f'{imgs_dir}/*.jpeg')\n",
    "    for file in tqdm.tqdm(files):\n",
    "        img = cv2.imread(file)\n",
    "        locations = fr.face_locations(img)\n",
    "        if(len(locations) > 0):\n",
    "            y1, x2, y2, x1 = locations[0]\n",
    "            face = img[y1:y2, x1:x2]\n",
    "            cv2.imwrite(file, face)\n",
    "    \n",
    "videos_to_images(real_dir, real_imgs_dir, images_per_vid=30)\n",
    "videos_to_images(attack_dir, attack_imgs_dir, images_per_vid=10)\n",
    "\n",
    "crop_face_images(real_imgs_dir)\n",
    "crop_face_images(attack_imgs_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse video data to tfrecord of (image, label) pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8370/8370 [00:00<00:00, 2058539.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] parsing images from /home/minhhieu/Desktop/Hieu/datasets/scene01/imgs/attack to tfrecords ... \n",
      "[INFO] Writing to tfrecord file : /home/minhhieu/Desktop/Hieu/datasets/MSU_MFSD_presentation_attack.tfrecord ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    if(isinstance(value, type(tf.constant(0)))):\n",
    "        value = value.numpy()\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def make_example(filename, label):\n",
    "    assert isinstance(filename, str) and isinstance(label, int)\n",
    "    \n",
    "    feature = {\n",
    "        'image/filename' : _bytes_feature(str.encode(filename)),\n",
    "        'image/encoded' : _bytes_feature(open(filename, 'rb').read()),\n",
    "        'image/label' : _int64_feature(label),\n",
    "    }\n",
    "    \n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "def parse_images_to_tfrecord(files, output_path, images_per_file=30,):\n",
    "    print(f'[INFO] parsing images from {os.path.dirname(files[0])} to tfrecords ... ')\n",
    "    \n",
    "    samples = []\n",
    "    for file in tqdm.tqdm(files):        \n",
    "        label = file.split('/')[-2]\n",
    "        label = 1 if label == 'attack' else 0 \n",
    "        \n",
    "        samples.append((file, label))\n",
    "    \n",
    "                \n",
    "    print(f'[INFO] Writing to tfrecord file : {output_path} ...')\n",
    "    with tf.io.TFRecordWriter(output_path) as writer:\n",
    "        for filename, label in samples:\n",
    "            tf_example = make_example(filename, label)\n",
    "            writer.write(tf_example.SerializeToString())\n",
    "            \n",
    "    print('DONE!')\n",
    "            \n",
    "attack_imgs_files = glob.glob(f'{attack_imgs_dir}/*.jpg')\n",
    "real_imgs_files = glob.glob(f'{real_imgs_dir}/*.jpg')\n",
    "parse_images_to_tfrecord(attack_imgs_files+real_imgs_files, tfrecord_output_path, images_per_file=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data back from tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_image(image):\n",
    "    mean = tf.math.reduce_mean(image)\n",
    "    std = tf.math.reduce_std(image)\n",
    "    \n",
    "    image = tf.math.subtract(image, mean)\n",
    "    image = tf.math.divide(image, std)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def normalize_image(image):\n",
    "    image = tf.math.subtract(image, 127.5)\n",
    "    image = tf.math.divide(image, 127.5)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def _parse_tfrecord(color_space=None):\n",
    "    def _parse_func(example_proto, img_dim=(128, 128), color_space=color_space):\n",
    "        feature_desc = {\n",
    "            'image/filename' : tf.io.FixedLenFeature([], tf.string),\n",
    "            'image/encoded' : tf.io.FixedLenFeature([], tf.string),\n",
    "            'image/label' : tf.io.FixedLenFeature([], tf.int64)\n",
    "        }\n",
    "\n",
    "        x = tf.io.parse_single_example(example_proto, feature_desc)\n",
    "        image = tf.image.decode_jpeg(x['image/encoded'])\n",
    "        image = tf.image.resize(image, img_dim)\n",
    "        image = tf.cast(image, dtype=tf.float32)\n",
    "        \n",
    "        ### Convert colorspace if needed ###\n",
    "        if(color_space is not None):\n",
    "            if(color_space == 'hsv') : image = tf.image.rgb_to_hsv(image)\n",
    "\n",
    "        ### Normalize/Standardization ###\n",
    "        image = standardize_image(image)\n",
    "        image = tf.convert_to_tensor(image)\n",
    "        depth = tf.ones((52,52,1))\n",
    "        if(x['image/label'] == tf.constant(1, dtype=tf.int64)): # if spoof -> depth is zero\n",
    "            depth = tf.zeros((52,52,1))\n",
    "        label = tf.one_hot(x['image/label'], depth=2)\n",
    "\n",
    "        return image, label, depth\n",
    "\n",
    "    return _parse_func\n",
    "\n",
    "def read_from_tfrecord(tfrecord_file, colorspace=None,batch_size=64, buffer_size=40000):\n",
    "    dataset_len = int(sum(1 for _ in tf.data.TFRecordDataset(tfrecord_file)))\n",
    "    parse_func = _parse_tfrecord(color_space=colorspace)\n",
    "    \n",
    "    num_batches = dataset_len // batch_size\n",
    "    train_size = int(num_batches * 0.7)\n",
    "    test_size = num_batches - train_size\n",
    "    \n",
    "    raw_dataset = tf.data.TFRecordDataset(tfrecord_file)\n",
    "    raw_dataset = raw_dataset.repeat()\n",
    "    raw_dataset = raw_dataset.shuffle(buffer_size=buffer_size)\n",
    "    \n",
    "    dataset = raw_dataset.map(parse_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    train_dataset = dataset.take(train_size)\n",
    "    test_dataset = dataset.skip(train_size)\n",
    "    \n",
    "    return dataset_len, train_dataset, test_dataset\n",
    "\n",
    "# dataset_len, train_dataset, test_dataset = read_from_tfrecord(tfrecord_output_path, batch_size=64, colorspace='hsv')\n",
    "# x, y, depth = next(iter(train_dataset))\n",
    "# x = x.numpy()[0]\n",
    "# print(y, depth)\n",
    "# plt.imshow(x)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create patch-based CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"PatchBasedCNN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "random_crop (RandomCrop)     (64, 96, 96, 3)           0         \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (64, 48, 48, 50)          4000      \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (64, 24, 24, 100)         125500    \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (64, 12, 12, 150)         375750    \n",
      "_________________________________________________________________\n",
      "sequential_3 (Sequential)    (64, 6, 6, 200)           751000    \n",
      "_________________________________________________________________\n",
      "sequential_4 (Sequential)    (64, 3, 3, 250)           1251250   \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (64, 2250)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, 1000)                2251000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (64, 1000)                4000      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (64, 1000)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (64, 400)                 400400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (64, 400)                 1600      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (64, 2)                   802       \n",
      "=================================================================\n",
      "Total params: 5,165,302\n",
      "Trainable params: 5,161,002\n",
      "Non-trainable params: 4,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class RandomCrop(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_shape, patch_dim):\n",
    "        super(RandomCrop, self).__init__()\n",
    "        self.patch_dim = patch_dim\n",
    "                \n",
    "    def call(self, inputs):\n",
    "        return tf.image.random_crop(inputs, size=self.patch_dim)\n",
    "\n",
    "\n",
    "def _conv_bn_pool_block(filters, kernel_size=5, pool_size=2):\n",
    "    block = Sequential([\n",
    "        Conv2D(filters, kernel_size=kernel_size, strides=1, padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=pool_size)\n",
    "    ])\n",
    "    \n",
    "    return block\n",
    "\n",
    "def patch_based_cnn(input_dim=(128, 128, 3), patch_dim=(96,96,3), batch_size=64, name='PatchBasedCNN'):\n",
    "    inputs = Input(shape=input_dim)\n",
    "    patch_inputs = RandomCrop(input_dim, patch_dim=(batch_size, patch_dim[0], patch_dim[1], patch_dim[2]))(inputs)\n",
    "    \n",
    "    x = _conv_bn_pool_block(50)(patch_inputs)\n",
    "    x = _conv_bn_pool_block(100)(x)\n",
    "    x = _conv_bn_pool_block(150)(x)\n",
    "    x = _conv_bn_pool_block(200)(x)\n",
    "    x = _conv_bn_pool_block(250)(x)\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    fc = Dense(1000, activation='relu')(x)\n",
    "    fc = BatchNormalization()(fc)\n",
    "    fc = Dropout(0.5)(fc)\n",
    "    \n",
    "    fc = Dense(400, activation='relu')(fc)\n",
    "    fc = BatchNormalization()(fc)\n",
    "    output = Dense(2, activation='softmax')(fc)\n",
    "\n",
    "    model = Model(inputs = inputs, outputs=output, name=name)\n",
    "    return model    \n",
    "\n",
    "model = patch_based_cnn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create depth-based CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"DepthBasedCNN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "sequential_5 (Sequential)    (None, 64, 64, 128)       112576    \n",
      "_________________________________________________________________\n",
      "sequential_6 (Sequential)    (None, 32, 32, 160)       811552    \n",
      "_________________________________________________________________\n",
      "sequential_7 (Sequential)    (None, 37, 37, 128)       774400    \n",
      "_________________________________________________________________\n",
      "sequential_8 (Sequential)    (None, 42, 42, 128)       737536    \n",
      "_________________________________________________________________\n",
      "sequential_9 (Sequential)    (None, 47, 47, 160)       1106240   \n",
      "_________________________________________________________________\n",
      "sequential_10 (Sequential)   (None, 52, 52, 320)       4147840   \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 52, 52, 1)         2881      \n",
      "=================================================================\n",
      "Total params: 7,693,025\n",
      "Trainable params: 7,693,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def _3conv_pool_block(filters, kernel_size=3, pool_size=2):\n",
    "    assert isinstance(filters, list) and len(filters) == 3\n",
    "    block = Sequential([\n",
    "        Conv2D(filters[0], kernel_size=kernel_size, strides=1, padding='same'),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        Conv2D(filters[1], kernel_size=kernel_size, strides=1, padding='same'),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        Conv2D(filters[2], kernel_size=kernel_size, strides=1, padding='same'),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        MaxPooling2D(pool_size=pool_size)\n",
    "    ])\n",
    "    \n",
    "    return block\n",
    "\n",
    "def _conv_convT_block(filters, conv_kernel=3, convT_kernel=6):\n",
    "    assert isinstance(filters, list) and len(filters) == 2\n",
    "    block = Sequential([\n",
    "        Conv2D(filters[0], kernel_size=conv_kernel, strides=1, padding='same'),\n",
    "        Conv2DTranspose(filters[1], kernel_size=convT_kernel, strides=1, padding='valid')\n",
    "    ])\n",
    "\n",
    "    return block\n",
    "\n",
    "def depth_based_cnn(input_shape=(128, 128, 3), name=\"DepthBasedCNN\"):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    x = _3conv_pool_block([64, 64, 128])(inputs)\n",
    "    x = _3conv_pool_block([128,256,160])(x)\n",
    "    x = _conv_convT_block([128, 128])(x)\n",
    "    x = _conv_convT_block([128, 128])(x)\n",
    "    x = _conv_convT_block([160, 160])(x)\n",
    "    x = _conv_convT_block([320, 320])(x)\n",
    "    output = Conv2D(1, kernel_size=3, strides=1, padding='same')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=output, name=name)\n",
    "    return model\n",
    "\n",
    "model = depth_based_cnn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine the two models and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"DepthBased_PatchBased_CNN\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "PatchBasedCNN (Functional)      (64, 2)              5165302     input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "DepthBasedCNN (Functional)      (None, 52, 52, 1)    7693025     input_12[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 12,858,327\n",
      "Trainable params: 12,854,027\n",
      "Non-trainable params: 4,300\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def full_model(input_dim=(128, 128, 3)):\n",
    "    inputs = Input(shape=input_dim)\n",
    "    \n",
    "    depth_cnn = depth_based_cnn()\n",
    "    patch_cnn = patch_based_cnn()\n",
    "    \n",
    "    spoof_score = patch_cnn(inputs)\n",
    "    depth_map   = depth_cnn(inputs)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=[spoof_score, depth_map], name='DepthBased_PatchBased_CNN')\n",
    "    return model\n",
    "\n",
    "losses = {\n",
    "    'PatchBasedCNN' : tf.keras.losses.BinaryCrossentropy(),\n",
    "    'DepthBasedCNN' : tf.keras.losses.MeanSquaredError()\n",
    "}\n",
    "\n",
    "optimizer = Adam(lr=0.0001, amsgrad=True, beta_1=0.5)\n",
    "\n",
    "model = full_model()\n",
    "model.compile(optimizer=optimizer, loss=losses)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "    Batch #1, depth loss = 0.3752802014350891, path loss = 0.12390800565481186, total = 0.49918821454048157\n",
      "    Batch #2, depth loss = 0.414543092250824, path loss = 0.13238564133644104, total = 0.5469287633895874\n",
      "    Batch #3, depth loss = 0.2534486651420593, path loss = 0.19448532164096832, total = 0.44793397188186646\n",
      "    Batch #4, depth loss = 0.13797500729560852, path loss = 0.14190071821212769, total = 0.2798757255077362\n",
      "    Batch #5, depth loss = 0.41948434710502625, path loss = 0.12218107283115387, total = 0.5416654348373413\n",
      "    Batch #6, depth loss = 0.2716611623764038, path loss = 0.16272607445716858, total = 0.4343872368335724\n",
      "    Batch #7, depth loss = 0.22607339918613434, path loss = 0.1834670901298523, total = 0.40954047441482544\n",
      "    Batch #8, depth loss = 0.33743685483932495, path loss = 0.16236276924610138, total = 0.49979960918426514\n",
      "    Batch #9, depth loss = 0.27310189604759216, path loss = 0.15228591859340668, total = 0.42538779973983765\n",
      "    Batch #10, depth loss = 0.2797226309776306, path loss = 0.1617891937494278, total = 0.4415118098258972\n",
      "    Batch #11, depth loss = 0.19533228874206543, path loss = 0.14228443801403046, total = 0.3376167416572571\n",
      "    Batch #12, depth loss = 0.1710185706615448, path loss = 0.16214701533317566, total = 0.33316558599472046\n",
      "    Batch #13, depth loss = 0.39431679248809814, path loss = 0.1422574371099472, total = 0.5365742444992065\n",
      "    Batch #14, depth loss = 0.21559210121631622, path loss = 0.17106835544109344, total = 0.38666045665740967\n",
      "    Batch #15, depth loss = 0.417161226272583, path loss = 0.15060169994831085, total = 0.5677629113197327\n",
      "    Batch #16, depth loss = 0.24431559443473816, path loss = 0.1987580955028534, total = 0.44307368993759155\n",
      "    Batch #17, depth loss = 0.4225265383720398, path loss = 0.20384307205677032, total = 0.6263695955276489\n",
      "    Batch #18, depth loss = 0.6539520025253296, path loss = 0.13364967703819275, total = 0.7876017093658447\n",
      "    Batch #19, depth loss = 0.2096865177154541, path loss = 0.16054266691207886, total = 0.37022918462753296\n",
      "    Batch #20, depth loss = 0.325461208820343, path loss = 0.1631782054901123, total = 0.4886394143104553\n",
      "    Batch #21, depth loss = 0.2888055443763733, path loss = 0.16290433704853058, total = 0.4517098665237427\n",
      "    Batch #22, depth loss = 0.3225749731063843, path loss = 0.1343734860420227, total = 0.456948459148407\n",
      "    Batch #23, depth loss = 0.45866164565086365, path loss = 0.133417010307312, total = 0.592078685760498\n",
      "    Batch #24, depth loss = 0.18631798028945923, path loss = 0.17336313426494598, total = 0.3596811294555664\n",
      "    Batch #25, depth loss = 0.3334009349346161, path loss = 0.2037331610918045, total = 0.5371341109275818\n",
      "    Batch #26, depth loss = 0.19942587614059448, path loss = 0.17242537438869476, total = 0.37185126543045044\n",
      "    Batch #27, depth loss = 0.2879222631454468, path loss = 0.18129342794418335, total = 0.4692156910896301\n",
      "    Batch #28, depth loss = 0.21551550924777985, path loss = 0.1265587955713272, total = 0.34207430481910706\n",
      "    Batch #29, depth loss = 0.20813915133476257, path loss = 0.1719820648431778, total = 0.38012123107910156\n",
      "    Batch #30, depth loss = 0.16063940525054932, path loss = 0.19103001058101654, total = 0.35166943073272705\n",
      "    Batch #31, depth loss = 0.3202519416809082, path loss = 0.10587089508771896, total = 0.42612284421920776\n",
      "    Batch #32, depth loss = 0.4780500531196594, path loss = 0.17219416797161102, total = 0.6502442359924316\n",
      "    Batch #33, depth loss = 0.31065547466278076, path loss = 0.19202913343906403, total = 0.5026845932006836\n",
      "    Batch #34, depth loss = 0.14510871469974518, path loss = 0.1525387167930603, total = 0.2976474165916443\n",
      "    Batch #35, depth loss = 0.2935057580471039, path loss = 0.16167615354061127, total = 0.45518189668655396\n",
      "    Batch #36, depth loss = 0.2829788029193878, path loss = 0.11488422751426697, total = 0.3978630304336548\n",
      "    Batch #37, depth loss = 0.2567152678966522, path loss = 0.2221640646457672, total = 0.47887933254241943\n",
      "    Batch #38, depth loss = 0.40678438544273376, path loss = 0.16217899322509766, total = 0.5689634084701538\n",
      "    Batch #39, depth loss = 0.3237941861152649, path loss = 0.2536170184612274, total = 0.5774111747741699\n",
      "    Batch #40, depth loss = 0.11528384685516357, path loss = 0.173285111784935, total = 0.28856897354125977\n",
      "    Batch #41, depth loss = 0.5151056051254272, path loss = 0.1429380178451538, total = 0.658043622970581\n",
      "    Batch #42, depth loss = 0.3456200361251831, path loss = 0.10810516774654388, total = 0.4537252187728882\n",
      "    Batch #43, depth loss = 0.23906542360782623, path loss = 0.12247207760810852, total = 0.36153751611709595\n",
      "    Batch #44, depth loss = 0.3485308289527893, path loss = 0.1846182942390442, total = 0.5331491231918335\n",
      "    Batch #45, depth loss = 0.1467505693435669, path loss = 0.22657306492328644, total = 0.37332361936569214\n",
      "    Batch #46, depth loss = 0.21206393837928772, path loss = 0.14285807311534882, total = 0.35492199659347534\n",
      "    Batch #47, depth loss = 0.2252039611339569, path loss = 0.16258928179740906, total = 0.38779324293136597\n",
      "    Batch #48, depth loss = 0.1505526304244995, path loss = 0.1718859225511551, total = 0.3224385380744934\n",
      "    Batch #49, depth loss = 0.20857959985733032, path loss = 0.1715448647737503, total = 0.38012444972991943\n",
      "    Batch #50, depth loss = 0.2023727148771286, path loss = 0.1997801810503006, total = 0.4021528959274292\n",
      "    Batch #51, depth loss = 0.40694645047187805, path loss = 0.13532528281211853, total = 0.5422717332839966\n",
      "    Batch #52, depth loss = 0.19183379411697388, path loss = 0.17093811929225922, total = 0.3627719283103943\n",
      "    Batch #53, depth loss = 0.3356179893016815, path loss = 0.17998692393302917, total = 0.5156049132347107\n",
      "    Batch #54, depth loss = 0.23564526438713074, path loss = 0.21671563386917114, total = 0.4523608982563019\n",
      "    Batch #55, depth loss = 0.41430673003196716, path loss = 0.12010324001312256, total = 0.5344099998474121\n",
      "    Batch #56, depth loss = 0.15529310703277588, path loss = 0.20580799877643585, total = 0.36110109090805054\n",
      "    Batch #57, depth loss = 0.5085104703903198, path loss = 0.16267521679401398, total = 0.6711856722831726\n",
      "    Batch #58, depth loss = 0.186538964509964, path loss = 0.143863245844841, total = 0.3304021954536438\n",
      "    Batch #59, depth loss = 0.1536971628665924, path loss = 0.1702892780303955, total = 0.3239864408969879\n",
      "    Batch #60, depth loss = 0.19795995950698853, path loss = 0.1611095815896988, total = 0.3590695261955261\n",
      "    Batch #61, depth loss = 0.4664706587791443, path loss = 0.16207264363765717, total = 0.6285433173179626\n",
      "    Batch #62, depth loss = 0.19725583493709564, path loss = 0.16999514400959015, total = 0.3672509789466858\n",
      "    Batch #63, depth loss = 0.18422801792621613, path loss = 0.19667911529541016, total = 0.3809071183204651\n",
      "    Batch #64, depth loss = 0.1533815860748291, path loss = 0.1289059817790985, total = 0.2822875678539276\n",
      "    Batch #65, depth loss = 0.264279305934906, path loss = 0.2080327272415161, total = 0.4723120331764221\n",
      "    Batch #66, depth loss = 0.25595226883888245, path loss = 0.1701766699552536, total = 0.42612892389297485\n",
      "    Batch #67, depth loss = 0.33043593168258667, path loss = 0.11067212373018265, total = 0.4411080479621887\n",
      "    Batch #68, depth loss = 0.1880199909210205, path loss = 0.18087032437324524, total = 0.36889031529426575\n",
      "    Batch #69, depth loss = 0.14968232810497284, path loss = 0.13058724999427795, total = 0.2802695631980896\n",
      "    Batch #70, depth loss = 0.10591389983892441, path loss = 0.20024921000003815, total = 0.30616310238838196\n",
      "    Batch #71, depth loss = 0.1265529990196228, path loss = 0.1874779611825943, total = 0.3140309453010559\n",
      "    Batch #72, depth loss = 0.35868561267852783, path loss = 0.16181227564811707, total = 0.5204979181289673\n",
      "    Batch #73, depth loss = 0.45368558168411255, path loss = 0.13630692660808563, total = 0.5899925231933594\n",
      "    Batch #74, depth loss = 0.12731653451919556, path loss = 0.14152604341506958, total = 0.26884257793426514\n",
      "    Batch #75, depth loss = 0.1538325995206833, path loss = 0.1513212025165558, total = 0.3051537871360779\n",
      "    Batch #76, depth loss = 0.19474761188030243, path loss = 0.16096462309360504, total = 0.35571223497390747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch #77, depth loss = 0.24274104833602905, path loss = 0.13089409470558167, total = 0.3736351430416107\n",
      "    Batch #78, depth loss = 0.20622959733009338, path loss = 0.14956827461719513, total = 0.3557978868484497\n",
      "    Batch #79, depth loss = 0.16658452153205872, path loss = 0.13125042617321014, total = 0.29783493280410767\n",
      "    Batch #80, depth loss = 0.23372139036655426, path loss = 0.15867149829864502, total = 0.3923928737640381\n",
      "    Batch #81, depth loss = 0.4161258041858673, path loss = 0.1313847154378891, total = 0.5475105047225952\n",
      "    Batch #82, depth loss = 0.16484759747982025, path loss = 0.21807944774627686, total = 0.3829270601272583\n",
      "    Batch #83, depth loss = 0.1633087545633316, path loss = 0.16806866228580475, total = 0.33137741684913635\n",
      "    Batch #84, depth loss = 0.411620557308197, path loss = 0.16352209448814392, total = 0.5751426219940186\n",
      "    Batch #85, depth loss = 0.1519843339920044, path loss = 0.16450132429599762, total = 0.3164856433868408\n",
      "    Batch #86, depth loss = 0.2095307856798172, path loss = 0.17505770921707153, total = 0.38458847999572754\n",
      "    Batch #87, depth loss = 0.08212020248174667, path loss = 0.1744988113641739, total = 0.25661900639533997\n",
      "    Batch #88, depth loss = 0.22716283798217773, path loss = 0.1438286304473877, total = 0.37099146842956543\n",
      "    Batch #89, depth loss = 0.17993375658988953, path loss = 0.22524906694889069, total = 0.4051828384399414\n",
      "    Batch #90, depth loss = 0.20209717750549316, path loss = 0.191675066947937, total = 0.3937722444534302\n",
      "    Batch #91, depth loss = 0.14575976133346558, path loss = 0.15697377920150757, total = 0.30273354053497314\n",
      "    Batch #92, depth loss = 0.20488199591636658, path loss = 0.21074123680591583, total = 0.4156232476234436\n",
      "    Batch #93, depth loss = 0.31214770674705505, path loss = 0.13419868052005768, total = 0.4463464021682739\n",
      "    Batch #94, depth loss = 0.33480048179626465, path loss = 0.11410853266716003, total = 0.4489090144634247\n",
      "    Batch #95, depth loss = 0.16614305973052979, path loss = 0.17327412962913513, total = 0.3394171893596649\n",
      "    Batch #96, depth loss = 0.21879728138446808, path loss = 0.11189910769462585, total = 0.3306964039802551\n",
      "    Batch #97, depth loss = 0.1524529755115509, path loss = 0.21596285700798035, total = 0.36841583251953125\n",
      "    Batch #98, depth loss = 0.18857944011688232, path loss = 0.15253205597400665, total = 0.3411114811897278\n",
      "    Batch #99, depth loss = 0.14976227283477783, path loss = 0.2107849419116974, total = 0.3605472147464752\n",
      "    Batch #100, depth loss = 0.5244340896606445, path loss = 0.11656635999679565, total = 0.6410004496574402\n",
      "    Batch #101, depth loss = 0.2975856065750122, path loss = 0.22829459607601166, total = 0.5258802175521851\n",
      "    Batch #102, depth loss = 0.3775820732116699, path loss = 0.0992821455001831, total = 0.476864218711853\n",
      "    Batch #103, depth loss = 0.19673216342926025, path loss = 0.20946291089057922, total = 0.4061950743198395\n",
      "    Batch #104, depth loss = 0.32924169301986694, path loss = 0.1716214269399643, total = 0.5008631348609924\n",
      "    Batch #105, depth loss = 0.17542764544487, path loss = 0.16235464811325073, total = 0.3377822935581207\n",
      "    Batch #106, depth loss = 0.22973623871803284, path loss = 0.18060928583145142, total = 0.41034552454948425\n",
      "    Batch #107, depth loss = 0.1316547393798828, path loss = 0.23524533212184906, total = 0.36690008640289307\n",
      "    Batch #108, depth loss = 0.19527578353881836, path loss = 0.18004710972309113, total = 0.3753228783607483\n",
      "    Batch #109, depth loss = 0.1707068681716919, path loss = 0.16442586481571198, total = 0.3351327180862427\n",
      "    Batch #110, depth loss = 0.26994454860687256, path loss = 0.16334527730941772, total = 0.4332898259162903\n",
      "    Batch #111, depth loss = 0.10155923664569855, path loss = 0.1798328012228012, total = 0.28139203786849976\n",
      "    Batch #112, depth loss = 0.24824441969394684, path loss = 0.14419390261173248, total = 0.3924383223056793\n",
      "    Batch #113, depth loss = 0.35905104875564575, path loss = 0.12435316294431686, total = 0.4834042191505432\n",
      "    Batch #114, depth loss = 0.15383946895599365, path loss = 0.17220108211040497, total = 0.3260405659675598\n",
      "    Batch #115, depth loss = 0.10641055554151535, path loss = 0.16273221373558044, total = 0.2691427767276764\n",
      "    Batch #116, depth loss = 0.1625310331583023, path loss = 0.16187502443790436, total = 0.32440605759620667\n",
      "    Batch #117, depth loss = 0.10479018092155457, path loss = 0.16153962910175323, total = 0.266329824924469\n",
      "    Batch #118, depth loss = 0.24896740913391113, path loss = 0.1900581270456314, total = 0.43902552127838135\n",
      "    Batch #119, depth loss = 0.21539199352264404, path loss = 0.13452541828155518, total = 0.3499174118041992\n",
      "    Batch #120, depth loss = 0.18935678899288177, path loss = 0.17056584358215332, total = 0.3599226474761963\n",
      "    Batch #121, depth loss = 0.17267580330371857, path loss = 0.10448955744504929, total = 0.27716535329818726\n",
      "    Batch #122, depth loss = 0.061692915856838226, path loss = 0.17308957874774933, total = 0.23478248715400696\n",
      "    Batch #123, depth loss = 0.31660062074661255, path loss = 0.12196045368909836, total = 0.4385610818862915\n",
      "    Batch #124, depth loss = 0.09473246335983276, path loss = 0.20295210182666779, total = 0.29768455028533936\n",
      "    Batch #125, depth loss = 0.10456862300634384, path loss = 0.17995905876159668, total = 0.2845276892185211\n",
      "    Batch #126, depth loss = 0.1489144265651703, path loss = 0.1881679743528366, total = 0.3370823860168457\n",
      "    Batch #127, depth loss = 0.25254589319229126, path loss = 0.22233621776103973, total = 0.4748821258544922\n",
      "    Batch #128, depth loss = 0.11632467806339264, path loss = 0.18935082852840424, total = 0.3056755065917969\n",
      "    Batch #129, depth loss = 0.1179637461900711, path loss = 0.17182022333145142, total = 0.28978395462036133\n",
      "    Batch #130, depth loss = 0.24519255757331848, path loss = 0.17926836013793945, total = 0.42446091771125793\n",
      "Epoch 2/100\n",
      "    Batch #1, depth loss = 0.20580875873565674, path loss = 0.1443120539188385, total = 0.35012081265449524\n",
      "    Batch #2, depth loss = 0.08972445130348206, path loss = 0.16124160587787628, total = 0.25096607208251953\n",
      "    Batch #3, depth loss = 0.15739846229553223, path loss = 0.22824232280254364, total = 0.38564079999923706\n",
      "    Batch #4, depth loss = 0.08525735139846802, path loss = 0.16129305958747864, total = 0.24655041098594666\n",
      "    Batch #5, depth loss = 0.23423655331134796, path loss = 0.1782665103673935, total = 0.41250306367874146\n",
      "    Batch #6, depth loss = 0.5985047817230225, path loss = 0.12218254059553146, total = 0.7206873297691345\n",
      "    Batch #7, depth loss = 0.2536061108112335, path loss = 0.22509372234344482, total = 0.47869983315467834\n",
      "    Batch #8, depth loss = 0.24624699354171753, path loss = 0.19606325030326843, total = 0.44231024384498596\n",
      "    Batch #9, depth loss = 0.09613952040672302, path loss = 0.14520084857940674, total = 0.24134036898612976\n",
      "    Batch #10, depth loss = 0.0390956774353981, path loss = 0.18537674844264984, total = 0.22447243332862854\n",
      "    Batch #11, depth loss = 0.18463370203971863, path loss = 0.133880615234375, total = 0.31851431727409363\n",
      "    Batch #12, depth loss = 0.1378219872713089, path loss = 0.12380772829055786, total = 0.26162970066070557\n",
      "    Batch #13, depth loss = 0.21118327975273132, path loss = 0.1429583579301834, total = 0.3541416525840759\n",
      "    Batch #14, depth loss = 0.2457980513572693, path loss = 0.14972664415836334, total = 0.39552468061447144\n",
      "    Batch #15, depth loss = 0.2150445133447647, path loss = 0.12278835475444794, total = 0.33783286809921265\n",
      "    Batch #16, depth loss = 0.15315788984298706, path loss = 0.18022063374519348, total = 0.33337852358818054\n",
      "    Batch #17, depth loss = 0.17891056835651398, path loss = 0.1877804547548294, total = 0.3666910231113434\n",
      "    Batch #18, depth loss = 0.14415907859802246, path loss = 0.13502974808216095, total = 0.2791888117790222\n",
      "    Batch #19, depth loss = 0.19389449059963226, path loss = 0.11910737305879593, total = 0.3130018711090088\n",
      "    Batch #20, depth loss = 0.4081747829914093, path loss = 0.15431423485279083, total = 0.5624890327453613\n",
      "    Batch #21, depth loss = 0.1811247169971466, path loss = 0.18009212613105774, total = 0.36121684312820435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch #22, depth loss = 0.1359390914440155, path loss = 0.20385272800922394, total = 0.33979183435440063\n",
      "    Batch #23, depth loss = 0.18059226870536804, path loss = 0.2087990641593933, total = 0.38939133286476135\n",
      "    Batch #24, depth loss = 0.10217852145433426, path loss = 0.17205068469047546, total = 0.2742291986942291\n",
      "    Batch #25, depth loss = 0.12012328207492828, path loss = 0.15105900168418884, total = 0.2711822986602783\n",
      "    Batch #26, depth loss = 0.2355806529521942, path loss = 0.25329798460006714, total = 0.48887863755226135\n",
      "    Batch #27, depth loss = 0.18251237273216248, path loss = 0.23588205873966217, total = 0.41839444637298584\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-5784f240dc62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         }\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'    Batch #{j+1}, depth loss = {depth_loss}, path loss = {patch_loss}, total = {total}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1698\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1699\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1700\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mreset_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1635\u001b[0m     \"\"\"\n\u001b[1;32m   1636\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1637\u001b[0;31m       \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1639\u001b[0m   def train_on_batch(self,\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/metrics.py\u001b[0m in \u001b[0;36mreset_states\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0mwhen\u001b[0m \u001b[0ma\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mevaluated\u001b[0m \u001b[0mduring\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \"\"\"\n\u001b[0;32m--> 247\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   3574\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly_outside_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3575\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtuples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3576\u001b[0;31m       \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3577\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3578\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0mvalue_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m       assign_op = gen_resource_variable_ops.assign_variable_op(\n\u001b[0m\u001b[1;32m    860\u001b[0m           self.handle, value_tensor, name=name)\n\u001b[1;32m    861\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mread_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py\u001b[0m in \u001b[0;36massign_variable_op\u001b[0;34m(resource, value, name)\u001b[0m\n\u001b[1;32m    140\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"AssignVariableOp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         tld.op_callbacks, resource, value)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print(f'Epoch {i+1}/100')\n",
    "    for j in range(dataset_len // batch_size):\n",
    "        images, labels, depths = next(iter(train_dataset))\n",
    "        y = {\n",
    "            'DepthBasedCNN' : depths,\n",
    "            'PatchBasedCNN' : labels\n",
    "        }\n",
    "        \n",
    "        total, depth_loss, patch_loss = model.train_on_batch(images, y)\n",
    "        print(f'    Batch #{j+1}, depth loss = {depth_loss}, patch loss = {patch_loss}, total = {total}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train two models separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
